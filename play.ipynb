{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1873ca0",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201fa60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math mode\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# We use a tiny vocab: 0-9, +, =, and space (pad)\n",
    "chars = \"0123456789+= \"\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "\n",
    "class Config:\n",
    "    vocab_size = len(chars)\n",
    "    n_embed = 256\n",
    "    n_heads = 4          \n",
    "    block_size = 16    \n",
    "    dropout = 0.05\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else 'cpu'\n",
    "\n",
    "Config = Config()\n",
    "print(\"Using device:\", Config.device)\n",
    "\n",
    "# Standard transformer components\n",
    "class Head(nn.Module):\n",
    "    \"\"\" One head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(Config.n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(Config.n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(Config.n_embed, head_size, bias=False)\n",
    "        self.register_buffer(\n",
    "            \"tril\", torch.tril(torch.ones(Config.block_size, Config.block_size))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        v = self.value(x) # (B,T,C)\n",
    "\n",
    "        # Compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2, -1) * C**-0.5 # (B,T,C) @ (B,C,T) -> (B,T,T)\n",
    "\n",
    "        # Apply the causal mask\n",
    "        # 'to ensure that the model only attends to past and present tokens, never future ones.'\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "\n",
    "        # Softmax normalization\n",
    "        wei = F.softmax(wei, dim=-1) # (B,T,T)\n",
    "        # wei = self.dropout(wei)\n",
    "\n",
    "        # Perform the weighted aggregation of the values\n",
    "        out = wei @ v # (B,T,T) @ (B,T,C) -> (B,T,C)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" A simple linear layer followed by a non-linearity \"\"\"\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4 * n_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embed, n_embed),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        head_size = Config.n_embed // Config.n_heads\n",
    "        self.sa = MultiHeadAttention(Config.n_heads, head_size)\n",
    "        self.ffwd = FeedForward(Config.n_embed)\n",
    "        self.ln1 = nn.LayerNorm(Config.n_embed)\n",
    "        self.ln2 = nn.LayerNorm(Config.n_embed)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [Head(head_size) for _ in range(num_heads)]\n",
    "        )\n",
    "        self.proj = nn.Linear(Config.n_embed, Config.n_embed)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n",
    "class RecurrentGPT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(Config.vocab_size, Config.n_embed)\n",
    "        self.position_embedding_table = nn.Embedding(Config.block_size, Config.n_embed)\n",
    "        \n",
    "        # Shared blocks\n",
    "        self.shared_sa = MultiHeadAttention(Config.n_heads, Config.n_embed // Config.n_heads)\n",
    "        self.shared_ffwd = FeedForward(Config.n_embed)\n",
    "        self.ln1 = nn.LayerNorm(Config.n_embed)\n",
    "        self.ln2 = nn.LayerNorm(Config.n_embed)\n",
    "        \n",
    "        self.ln_f = nn.LayerNorm(Config.n_embed) # final layer norm\n",
    "        self.lm_head = nn.Linear(Config.n_embed, Config.vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None, recur_depth=1):\n",
    "        B, T = idx.shape\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        # 1.Embeddings\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=Config.device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        \n",
    "        # 2. Recurrent Depth loop\n",
    "        # so instead of : for layer in self.laayers:\n",
    "        # we do\n",
    "        for _ in range(recur_depth):\n",
    "            x = x + self.shared_sa(self.ln1(x))\n",
    "            x = x + self.shared_ffwd(self.ln2(x))\n",
    "        \n",
    "        # 3. Final layer norm and head\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d747f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# GENERATOR (2 Digits ONLY)\n",
    "def generate_math_batch(batch_size=32):\n",
    "    inputs, targets = [], []\n",
    "    for _ in range(batch_size):\n",
    "        # 2 DIGITS (e.g. 50+50=100)\n",
    "        # This is easy enough to learn in 5 minutes\n",
    "        a = random.randint(10, 99)\n",
    "        b = random.randint(10, 99)\n",
    "        \n",
    "        problem = f\"{a}+{b}={a+b}\"\n",
    "        problem = problem.ljust(Config.block_size, ' ') \n",
    "        \n",
    "        encoded = [stoi[p] for p in problem]\n",
    "        x = torch.tensor(encoded[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(encoded[1:], dtype=torch.long)\n",
    "        inputs.append(x)\n",
    "        targets.append(y)\n",
    "        \n",
    "    return torch.stack(inputs).to(Config.device), torch.stack(targets).to(Config.device)\n",
    "\n",
    "# TRAINING LOOP\n",
    "model = RecurrentGPT().to(Config.device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3) # Standard LR\n",
    "\n",
    "print(\"Starting Training (2-3 Digit Addition)...\")\n",
    "print(\"We need Loss < 0.1 for this to work.\\n\")\n",
    "\n",
    "for step in range(3001):\n",
    "    xb, yb = generate_math_batch(64)\n",
    "    train_depth = random.randint(1, 8) \n",
    "    \n",
    "    logits, loss = model(xb, targets=yb, recur_depth=train_depth)\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 500 == 0:\n",
    "        print(f\"Step {step}: Loss {loss.item():.4f} (Depth {train_depth})\")\n",
    "\n",
    "\n",
    "# EVALUATION \n",
    "print(\"\\nCHECKING PREDICTIONS \")\n",
    "xb, yb = generate_math_batch(1)\n",
    "with torch.no_grad():\n",
    "    logits, _ = model(xb, recur_depth=8)\n",
    "    preds = torch.argmax(logits, dim=2)\n",
    "\n",
    "input_str = \"\".join([itos[i.item()] for i in xb[0]])\n",
    "pred_str = \"\".join([itos[i.item()] for i in preds[0]])\n",
    "# Note: Prediction is shifted by 1, so we align visually\n",
    "print(f\"Input: {input_str}\")\n",
    "print(f\"Pred:  {pred_str}\")\n",
    "\n",
    "\n",
    "print('\\nLets see accuracy at different depths:')\n",
    "# EVALUATION (SMART VERSION) \n",
    "def evaluate_smart(depth):\n",
    "    # Test on 200 samples\n",
    "    total = 200\n",
    "    correct = 0\n",
    "    xb, yb = generate_math_batch(total)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits, _ = model(xb, recur_depth=depth)\n",
    "    \n",
    "    preds = torch.argmax(logits, dim=2)\n",
    "    \n",
    "    for i in range(total):\n",
    "        # Convert to strings\n",
    "        target_str = \"\".join([itos[x.item()] for x in yb[i]])\n",
    "        pred_str = \"\".join([itos[x.item()] for x in preds[i]])\n",
    "        \n",
    "        # Split at '=' to ignore the prompt\n",
    "        if '=' in target_str:\n",
    "            # We only check the part AFTER the equals sign\n",
    "            target_ans = target_str.split('=')[1].strip()\n",
    "            \n",
    "            if '=' in pred_str:\n",
    "                pred_ans = pred_str.split('=')[1].strip()\n",
    "                \n",
    "                # Check if answers match\n",
    "                if target_ans == pred_ans:\n",
    "                    correct += 1\n",
    "            \n",
    "    return correct / total\n",
    "\n",
    "print(\"Calculating Accuracy on Answer Only (Ignoring Prompt Errors)...\")\n",
    "usable_accuracies = []\n",
    "for d in [1, 2, 4, 8]:\n",
    "    acc = evaluate_smart(d)\n",
    "    usable_accuracies.append(acc*100)\n",
    "    print(f\"Depth {d:2d}: Accuracy = {acc*100:.1f}%\")\n",
    "    \n",
    "# PLOTTING RESULTS\n",
    "depths = ['Depth 1', 'Depth 2', 'Depth 4', 'Depth 8']\n",
    "accuracy = usable_accuracies\n",
    "colors = ['#ff9999', '#66b3ff', '#99ff99', '#66b3ff'] # Red for fail, Blue/Green for success\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(depths, accuracy, color=colors, edgecolor='black')\n",
    "\n",
    "plt.title('Impact of Recurrent Depth on Arithmetic Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.ylim(0, 110)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2.0, height + 2, f'{height}%', \n",
    "             ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.savefig('demo_results.png', dpi=300)\n",
    "print(\"Chart saved as demo_results.png!\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fff11f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
